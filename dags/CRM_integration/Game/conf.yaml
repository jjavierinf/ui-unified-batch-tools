# config.yaml
expected_workload: low
#   - "high" => Use Spark with 4 cores for high-performance tasks.
#   - "medium" => Use Spark with 2 cores for moderate workloads.
#   - "low" => Use Python for lightweight tasks with minimal resource usage.
# Set the expected workload to control the execution engine and resource allocation.expected_workload: high 

source:
  type: sql_server  # postgres or sql_server
  conn: sqlserver_GamingIntegration_conn
  table: Game
  schema: gc
  query: SELECT * FROM gc.Game
  source_timezone: US/Eastern
  incremental_update_field: None 

target:
  type: starrocks
  database: db_stage
  table: GamingIntegration_gc_Game

dag_type: snapshot  # Specify the job type: 'snapshot' or 'incremental'

dag_config:
  dag_name: dag_CRM_integration_gc_Game
  integration_name: CRM_integration
  dag_description: DAG to replicate GamingIntegration Game for CRM_integration
  dag_schedule_interval: 5 0,3,6,9,12,15,18,21 * * *
  dag_catchup: False
  dag_max_active_runs: 1
  dag_tags:
    - CRM_integration
    - snapshot
  dag_owner: a.kwiek # TODO validate this
  dag_start_date: "2023-12-22T00:00:00"