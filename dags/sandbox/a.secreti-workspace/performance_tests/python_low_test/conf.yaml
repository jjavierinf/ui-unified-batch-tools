# config.yaml
expected_workload: low
#   - "high" => Use Spark with 4 cores for high-performance tasks.
#   - "medium" => Use Spark with 2 cores for moderate workloads.
#   - "low" => Use Python for lightweight tasks with minimal resource usage.
# Set the expected workload to control the execution engine and resource allocation.expected_workload: high 

source:
  type: postgres  # postgres or sql_server
  conn: postgres_production_conn
  table: form_submission_select_options
  schema: chat
  query: SELECT * FROM chat.form_submission_select_options 
  source_timezone: UTC
  incremental_update_field: None 

target:
  type: starrocks
  database: db_stage_DEVELOP
  table: python_low_test

dag_type: snapshot  # Specify the job type: 'snapshot' or 'incremental'

dag_config:
  dag_name: python_low_test_dag
  integration_name: Test
  dag_description: Test
  dag_schedule_interval: 0 9 * * *
  dag_catchup: False
  dag_max_active_runs: 1
  dag_tags:
    - TEST
  dag_owner: a.secreti
  dag_start_date: "2024-04-17T00:00:00"